---
title: "aer13_OriginalHomeworkCode_05"
author: "Abby_Robinson"
date: "11/10/2021"
output: html_document
---

#Boots for Days!
##Bootstrapping Standard Errors and CIs for Linear Models.

```{r}
library(curl)
```

load KamilarAndCooperData.csv dataset into R markdown file 
```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
k <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
k
```

[1] Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}
model <- lm(log(HomeRange_km2) ~ log(Body_mass_female_mean), data = k)
model
##the intercept is -9.441 and the slope is 1.036

plot(model)  ##residuals look randomly distributed and the QQ plot is linear 
```
#cece comments: looks good, I got almost the same slope and intercept, and my qq plot was linear too. I would just exclude the NAs here instead, use "na.action = na.exclude" after data=k. Its a lot easier than the code you did below
[2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

subset and rename  home range and body mass data and remove NAs
```{r}
home <- k$HomeRange_km2
home
home <- na.omit(home)
mass <- k$Body_mass_female_mean
mass <- na.omit(mass)
mass
pop.data <- as.data.frame(cbind(mass, home))
```

take a sample of 10 from the population 
```{r}
sample.data <- pop.data[sample(nrow(pop.data), 10, replace = TRUE),]
sample.data
```

```{r}
sample.model <- lm(log(home) ~ log(mass), data = sample.data)
sample.model
```
#cece comments: I think you may have done something wrong when you removed the NAs from the sample as your intercept and slope are off from what I have and what I've seen on others work.I'm not completely sure why you took a sample of 10 from the pop also. 


```{r}
# Containers for the coefficients
sample_coef_intercept <- NULL
sample_coef_slope <- NULL

for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = sample.data[sample(1:nrow(sample.data), nrow(sample.data), replace = TRUE), ]
  
  #Running the regression on these data
  model_bootstrap <- lm(home ~ mass, data = sample_d)
  
  #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, model_bootstrap$coefficients[1])
  
  sample_coef_slope <-
    c(sample_coef_slope, model_bootstrap$coefficients[2])
}
###Source: https://towardsdatascience.com/bootstrap-regression-in-r-98bfe4ff5007
```

# I think your code itself works but I did it differently so I dont know for sure. But again your variables are off so the results when you run the "sampe_coef_intercept and slope" outputs are different. 

call intercept coefficient sampling distribution 

```{r}
sample_coef_intercept
```


call slope coefficient sampling distribution 
```{r}
sample_coef_slope
```
# Cece: I believe to call slope and intercept for these variables you need to use i.set[i] <- a[1,] for intercept and s.set[i] <- a[2,] for slope. You can't just call the variable itself. 


Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

standard deviation 
```{r}
sd(sample_coef_intercept) #standard deviation for the intercept coefficient 
sd(sample_coef_slope) #standard deviation for the slope coefficient
```

95% CI
```{r}
quantile(sample_coef_intercept, c(0.025, 0.975))
##Got this from module 7, not sure if its right... 
```
#cece: I believe you need CIs for both B0 and B1

##How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

error seems higher in my sample disribution, but I also only sampled 10 individuals in my bootstrap, so these number might be more similar if a took a larger sample? 

```{r}
summary(model)
```

##How does the latter compare to the 95% CI estimated from your entire dataset?

My 3Q confidence interval is higher than that of the original model with the entire dataset, but agian this might be because I have a small sample number 

#Cece: Make sure you call the CI for the original model so you can compare it, I don't see code for this. Use confint(model,.95)

##Challenges:

1. I got an error when I tried to sample from the whole population because there were too many NAs in the dataset and the sample was only pulling NAs values, but I removed the NAs and that fixed the problem 

2. I originally had the "sample.data" code inside the bootstrap loop, but this was just giving the same number 1000 times when I ran the bootstrap, so I put that code outside of the actual bootstrap loop and that seemed to fix the problem! 


